Chatbot using LLM

This project demonstrates a simple chatbot using the Llama 3.1 8B LLM and the Groq API, integrated into a Streamlit application.

Overview

The chatbot provides a conversational interface where users can interact with a large language model to ask questions and receive responses. The backend uses the Llama 3.1 8B model provided by Groq Cloud, and the frontend is built with Streamlit for a user-friendly interface.

![Screenshot (127)](https://github.com/user-attachments/assets/fc6f9649-04cd-472f-9c49-44b717e59caf)


Technologies Used

- Groq Cloud: Provides the large language model (Llama 3.1 8B) used for generating responses.
- Llama 3.1 8B LLM: The large language model powering the chatbot's natural language processing capabilities.
- Streamlit: A Python library used to create the interactive web interface.

Features

- Interactive Chat Interface: Allows users to type questions and receive answers in a conversational format.
- Real-time Response Generation: Leverages the Llama 3.1 8B model to generate responses based on user input.
- Session Management: Maintains chat history within the user's session for a seamless conversational experience.


Usage

1. Open the Streamlit app in your browser.
2. Type your question or message in the input box and press Enter.
3. The chatbot will respond in the chat window.

References

- [Groq Cloud](https://groq.com/)
- [Llama 3.1 8B LLM](https://llama.com/)
- [Streamlit](https://streamlit.io/)




